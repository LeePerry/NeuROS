
TODO:

Add lit review that justify the use of unit testing to reduce cost in software development.
Addpotential lit review on priority queues - briefly explain our simple one.

Potentially lit review for graph validation? Can we use any existing technique to show that all
inputs will be provided by at least one node? i.e. the project structure makes sense?

What happens if the user defines callbacks for inputs which do not exist? Vice versa? Should we
issue a warning in any of those cases?

ROS Workspaces & Package Management:

 * Standard ROS projects require the creation of a workspace (directory) within which all nodes
   are defined and implemented.
 * This workspace must then be built via the ROS build tool before it is known to the ROS package
   manangement system.
 * It is possible to leverage containerisation and volume mounting, in order to avoid every user
   having to build their NeuROS project in this way.
   - A ROS workspace containing a single generic node is built during the installation phase of NeuROS.
   - This single node launches and is passed all project configuration which relates to it.
   - It then includes the NeuROS plugin, registeres all callback hooks and fires initialisation.
   - Thus every NeuROS container is running the same generic node with a different user plugin.

TTY:

 * There are many tools for managing docker containers, notably docker-compose
 * We want to be able to exit all NeuROS nodes by issuing Ctrl+C from the terminal
 * Since the main process (launch.py) forks off multiple docker containers, only one of the docker
   containers processes are in the foreground process group. This means that when Ctrl+C is signalled
   only the NeuROS nodes in one of the docker nodes are terminated.
 * In order to remedy this issue, the launch.py script must notice when any of the laucnhed nodes exit,
   and use that as a trigger to shutdown the remaining nodes via a SIGKILL.
 * There appears to be a further problem with Docker / ROS2 nodes interacting and breaking the tty.
   This is difficult to diagnose and fix, since the problem occurs in 3rd party software somewhere, and
   so as a work-around we issue "stty sane" before exiting launch.py
 * In general this gives nice session mangement, where all NeuROS processes can be cleanly stopped when
   the user issues a Ctrl+C.

Plugins:

  * Simplified integration via the common project directory
  * Explain how the import/bootstrap process works etc...
  * Also cover both standard and custom message types and how they are supported.
  * ...
  *

Callbacks:

  * Services suck - Async is the way to go - See previous notes (blocking/waiting causes deadlocks)
    - ROS executors, Multithreaded executor, services, mutexes and deadlocks.
    - If one callback is waiting to publish a message and it blocks a mutex, that means that thread
      cannot receive messages to tell it the subscribers are ready i.e. it is deadlocked forever.
      Therefor we need Multithreaded executors but that requires users code to be thread safe, as
      callbacks will be invoked from different threads in a relatiely ad-hoc fashion.
    - This is all a horrible mess that will likely confuse userss and cause bugs, therefor a fully
      async architecture was implemented.
  * Any function with it's inputs satisfied (i.e. received or optional) and it's output not saturated
    (i.e. discard_limit has not been reached) is invoked whenever we recieved an ack from a subscriber
    or a registration.
  * This allows different invocation frequencies between functions
  * Decreases the impact of adding a new function (all functions should ideally be kept relatiely short)
  * Priority Queue ensures that callbacks who haven't fired in a while are prioritised first in the
    next round
  * Loop-back message ensures that new pending messages are processed even when there are functions "ready"
    to fire. e.g. in the case where we have a function which accepts an optional input and returns it as
    an optional output, if we haven't received the input we would loop infinitely firing that callback
    forever since it can never saturate it's output (input and output are always both None). By iterating
    through the callbacks once and then triggering a loop-back message, we allow and new inputs to be
    processed, and therefor allow the output to saturate.
  * Callbacks can be registered as "on_initilisation" and once invoked these are immediately retired and
    never considered again. Furthermore these are guaranteed to execute before any other callbacks.
  * Callbacks can also be registered "on_tick" which means they are invoked at regular intervals
    (using ROS timers). They cannot take any other inputs, and should there output be saturated they are
    further delayed until it is ready (which is necessary to not break the requirements of the rest
    of the system. If deemed not suitable a user can always output from that node with no discard_limit).
  * Explain acknowledgements / registration.

TCP / UDP:

 * Explain discard_limit
 * Can we profile this? Would be great to show how it impacts performace in a trivial case.
 * Potentially add lit review that shows the trade off between TCP and UDP in terms of reliability
   and data throughput.
   e.g.
https://d1wqtxts1xzle7.cloudfront.net/57982039/IJET-23739-libre.pdf?1544648596=&response-content-disposition=inline%3B+filename%3DPerformance_Comparison_between_TCP_and_U.pdf&Expires=1695639122&Signature=WnBnSkMbfh5bfbpfaH2WMbyXNCSKwHNMZsUIMvDBbgubgK6NCEOm62mhu2lYUI8q0pSgkxhWZxMVb9aWLjfQ7THJVp-C3Z9VO9y4FTIvh5xWi6-EF~Do8aMS6eru5VMScLyw-ERxPZGFPV8oM~kJvDUz2Q5t3a75bcHRgVMHQ95-sku4h2H-GN9NoBOWxFn~yUoNKxgjALVFTRn1OVWU6XOwpZurXsDex20maqDj9ixPyqPkzmzZsaoFzutzZeleIbG0sElycfPlgSQx4rbbRY3YJJoHtDVvpxBmU9rdFm1Y3fRSpBP5uUgH3WY2TAHf49rcVi8OEw0B~BjQpa42oQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA

Gazebo:

 * Why Ignition? https://robotology.github.io/gym-ignition/master/why/why_ignition_gazebo.html

 * There are a vast number of potential launch options including (at minimum): gazebo --headless,
   gz server, xml launch file, python launch file, C++ launch file, Python API and C++ API.
   - Furthermore, robots can either be included inside the world file, launched via XML / Python /
     C++ launch files, or using the gz service.

   - Running Gazebo outside of Python/C++ doesn't provide strict programmatic control
     (WRONG - it does via the addition of a plugin
     http://classic.gazebosim.org/tutorials?tut=plugins_world_properties&cat=write_plugin. However this
     would require all users to add this plugin, or possibly load through the command line somehow?), and
     therefor the decision was made to use the Python API, which integrates nicely with the rest of the
     project.

     + Specifically, this method was deemed better than the C++ API as it requires no separate build
       stage, and is thus easier for users to install.
     + However, commands can be made and state cannot be retrieved via the Python API. Therefor it was
       necessary to implement these via standard ROS topics and use the Gazebo <-> ROS bridge. (Since
       you cannot subscribe directly to the Gazebo topics from the Python client).
     + Launching and management of the Gazebo <-> ROS bridge was implemented in the NeuROS Gazebo
       wrapper, with the related Gazebo types requiring definition alongside thir ROS counterparts in
       the NeuROS project file. This approach attempts to hide as much of the implementation detail
       from users as is technically feasible, to help increase ease-of-use and decoupling.
     + Using ROS for commands/state also means that any existing 3rd-party non-NeuROS componants can
       be integrated into the system easily, albeit with the obvious penalty of losing the internal
       NeuROS synchonrisation features. (Note that any externally received ROS messages are assumed
       to be recieved by a node called "__unknown_external_source__", this has slight impact on the
       calculation of "All"-modified inputs, as all external sources are treated equivalent.)
     + Finally, launching of robots was implemented by wrapping the gz service command line tool as
       part of the NeuROS Gazebo wrapper. Again this decision was made in order to maximise
       flexibility, ease-of-use and decoupling. If a user has included their robot inside the world
       file then they simply do not invoke the spawn_entity method. Launch files cannot be used
       since we are using the Python API for launching Gazebo. Using the commandline option likely
       has a small performance-hit from the launching of an additional process, but it seems unlikely
       to be a significant problem, given that spawning a robot is a rare thing to do.

 * Complex situation regarding names, formaly "gazebo", new version was briefly "ignition",
   then renamed and both refered to as "gazebo classic" and "gazebo" respectively.
   - Throughout the project it is referred to simply as "gazebo", with no indication of version intended.

 * Since this version has been significantly rewritten, there are lots of bugs and missing features.
   - For example, a long standing bug where subscriber topics are not listed by commandline tools
     https://robotics.stackexchange.com/questions/104316/joint-position-controller-plugin-doesnt-subscribe-to-any-topics
   - Second, JointPosition components appear to have no impact when added from a plugin
   - Many classic materials missing (see material translation)

 * This page indicates that the most recent version of gazebo (using the new gz.sim namespaces)
   are not fully compatible with any version of ROS: https://gazebosim.org/docs/garden/ros_installation
   - Despite this, the decision was made to use the latest version of both, with a number of reasons
     and mitigations:
     - Publishing a tool which contains the latest versions of the software should be prefered where
       possible.
       + Likely more future-proof (i.e. be more similar/compatible with future versions).
       + Likely includes more features/better performance etc.
     - All users code is intended to interact with Gazebo via the NeuROS Gazebo wrapper, which helps to
       decouple it from a specific Gazebo API version. (This allows us to easily downgrade/upgrade if/when
       any incompatibilities/bugs are realised.)
     - New versions of Gazebo are fairly trivial to support by updating the neuros_gazebo Dockerfile and
       Gazebo wrapper.
     - During testing of this combination, no problems were found. Up until the point of writing the
       software continues to work entirely as expected. It is not clear what incompatibilities are
       referred to by the linked page.

 * Porting the WhiskEye Plugin involved a total-rewrite, since the C++ API is unrecognisable.
   - Joint Control was replaced with Plugins
   - gz-sim-joint-controller-system (Set either force (torque?) or velocity to specific joint)
   - gz-sim-joint-position-controller-system (Set joint position, allegedly)
   - gz-sim-joint-trajectory-controller-system (Complex motion involving multiple co-ordinated joints
       being manipulated in various ways over specified duration of time.)

 * The system plugins are written to expect input from the transport only - in many cases this means
   manually overwriting the component value, for which there is a corresponding plugin, will do absolutely
   nothing since it immediately gets reset by the plugin. This is indeed the case for JointVelocityCmd.
   THIS MEANS A SENSOR IS EITHER CONTROLLED BY A GAZEGO (SDF) PLUGIN OR BY A USER PLUGIN = NEVER BOTH!
 * JointPositionController is actually written in such a way that it uses PID to calculate a velocity in order
   to achieve the desired position. it does NOT set the position directly, as this would be a significant cause
   of physicaly DISCONTINUITIES in the simulation (causing strange bugs and breaking the physics engine).
   https://github.com/gazebosim/gz-sim/blob/gz-sim7/src/systems/joint_position_controller/JointPositionController.cc

Options are:
    1. Use only the plugins and communicate via transport messages.
        * This would mean that the execution is somewhat non-deterministic.
    2. Write a plugin that receives a single message indicating position / velocity and outputs a single message
       containing all sensor data on every tick.
        * This would allow us to block in Gazebo for receipt of the control and in NeuROS for receipt of the
          sensor data and all would be fully deterministic.

Examples:

 * Serve as both manual integration tests and step-by-step introduction to features
 * Explain each...
 
Strict control vs real time:
 
 * Both supported via various messaging and Gazebo options
 * Gazebo (and thus NeuROS) supports "play forever in non-blocking thread" (async),
   which then allows the user full control over the GUI - pause, play, speed etc.
 * Gazebo (and thus NeuROS) also supports "progress the simulation by x time increment" (sync),
   which removes user playback control from the GUI (i.e. buttons have no effect).
 * This proves the greatest flexibility out of any existing setup!

Deterministic Execution:

  https://www.youtube.com/watch?v=II8yCw5tPE0

 * Internally, NeuROS can be configured in such a way as to be 100% deterministic. Any configuration
   with no external inputs/outputs and all connections with discard_limit=0 will be deterministic.

 * NeuROS *CAN* be configured in such a way as to be *almost* deterministic, even when interfacing
   with systems that communicate over external inputs and outputs, such as Gazebo e.g. if the Gazebo
   step function requires all Gazebo outputs before the next invocation. This pattern can be used
   to effectively synchronise communiction between NeuROS and any external process.
   - See the 3_physics_simulation example for a demonstration of this pattern.
     Note that in this case the simulator step function are marked as optional, since they are not
     generated in every step. However, the simulator will still block if there are any NeuROS nodes
     that are still busy processing this data.
   - Note that this is still not 100% deterministic, as the delivery of messages from NeuROS back into
     Gazebo cannot be synchonrised with the next step invocation. Sometimes we might step before Gazebo
     receives our message and other times afterward. It does however still guarantee that the simulation
     doesn't run ahead by any more than a single step. In practice this might mean that a control command
     arrives one step later or earlier.
   - Once the Gazebo Python API becomes more mature, it will be possible to make this fully deterministic
     by replacing the network-based communication with direct calls to the API. This is already possible
     for a limited number of use cases (e.g. world gravity) and will become more widespread as the API
     matures.
   - It would be theoretically possible for a user of NeuROS to write their own Gazebo plugin and
     corresponding Python bindings which allowed them to communicate between Gazebo and NeuROS in a
     fully deterministic manner. However this was deemed outside the scope of the project, since it is an
     enourmous amount of work to implement in a generic fashion and will eventually be covered by the
     standard Gazebo Python API anyway.

 * Alternatively NeuROS can be configured entirely non-deterministicly e.g. when discard_limit is not
   specified functions will be called reapeatedly with complete disregard to the state of their subscribers.
   In this case NeuROS uses UDP communication and thus does not even guarantee delivery of messages, which
   may be desirable for certain applications.



